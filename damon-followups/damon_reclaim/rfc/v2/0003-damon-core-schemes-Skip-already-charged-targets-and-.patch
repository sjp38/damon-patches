From 9cf8c71461cd115dbe58278e7ad3bdaf96ad9096 Mon Sep 17 00:00:00 2001
From: SeongJae Park <sjpark@amazon.de>
Date: Wed, 26 May 2021 14:30:42 +0000
Subject: [RFC v2 03/14] damon/core/schemes: Skip already charged targets and
 regions
To: akpm@linux-foundation.org
Cc: Jonathan.Cameron@Huawei.com,
    acme@kernel.org,
    alexander.shishkin@linux.intel.com,
    amit@kernel.org,
    benh@kernel.crashing.org,
    brendanhiggins@google.com,
    corbet@lwn.net,
    david@redhat.com,
    dwmw@amazon.com,
    elver@google.com,
    fan.du@intel.com,
    foersleo@amazon.de,
    greg@kroah.com,
    gthelen@google.com,
    guoju.fgj@alibaba-inc.com,
    jgowans@amazon.com,
    mgorman@suse.de,
    minchan@kernel.org,
    mingo@redhat.com,
    namhyung@kernel.org,
    peterz@infradead.org,
    riel@surriel.com,
    rientjes@google.com,
    rostedt@goodmis.org,
    rppt@kernel.org,
    shakeelb@google.com,
    shuah@kernel.org,
    sj38.park@gmail.com,
    snu@zelle79.org,
    vbabka@suse.cz,
    vdavydov.dev@gmail.com,
    zgf574564920@gmail.com,
    linux-damon@amazon.com,
    linux-mm@kvack.org,
    linux-doc@vger.kernel.org,
    linux-kernel@vger.kernel.org

If DAMOS stopped applying action to memory regions due to the speed
limit, it does nothing until next charge window starts.  Then, it starts
the work from the beginning of the address space.  If there is a huge
memory region at the beginning of the address space and it fulfills the
scheme target data access pattern, the action will applied to only the
region.

This commit mitigates the case by skipping memory regions that charged
in previous charge window at the beginning of current charge window.

Signed-off-by: SeongJae Park <sjpark@amazon.de>
---
 include/linux/damon.h |  5 +++++
 mm/damon/core.c       | 21 +++++++++++++++++++++
 2 files changed, 26 insertions(+)

diff --git a/include/linux/damon.h b/include/linux/damon.h
index 35068b0ece6f..0df81dd2d560 100644
--- a/include/linux/damon.h
+++ b/include/linux/damon.h
@@ -104,6 +104,8 @@ struct damos_speed_limit {
 /* private: for limit accounting */
 	unsigned long charged_sz;
 	unsigned long charged_from;
+	struct damon_target *charge_target_from;
+	unsigned long charge_addr_from;
 };
 
 /**
@@ -331,6 +333,9 @@ struct damon_ctx {
 #define damon_prev_region(r) \
 	(container_of(r->list.prev, struct damon_region, list))
 
+#define damon_last_region(t) \
+	(list_last_entry(&t->regions_list, struct damon_region, list))
+
 #define damon_for_each_region(r, t) \
 	list_for_each_entry(r, &t->regions_list, list)
 
diff --git a/mm/damon/core.c b/mm/damon/core.c
index 4ac4a9aa2514..5864b63c18f9 100644
--- a/mm/damon/core.c
+++ b/mm/damon/core.c
@@ -107,6 +107,8 @@ struct damos *damon_new_scheme(
 	scheme->limit.ms = limit->ms;
 	scheme->limit.charged_sz = 0;
 	scheme->limit.charged_from = 0;
+	scheme->limit.charge_target_from = NULL;
+	scheme->limit.charge_addr_from = 0;
 
 	return scheme;
 }
@@ -558,6 +560,21 @@ static void damon_do_apply_schemes(struct damon_ctx *c,
 		if (limit->sz && limit->charged_sz >= limit->sz)
 			continue;
 
+		if (limit->charge_target_from) {
+			if (t != limit->charge_target_from)
+				continue;
+			if (r == damon_last_region(t)) {
+				limit->charge_target_from = NULL;
+				limit->charge_addr_from = 0;
+				continue;
+			}
+			if (limit->charge_addr_from &&
+					r->ar.start < limit->charge_addr_from)
+				continue;
+			limit->charge_target_from = NULL;
+			limit->charge_addr_from = 0;
+		}
+
 		sz = r->ar.end - r->ar.start;
 		/* Check the target regions condition */
 		if (sz < s->min_sz_region || s->max_sz_region < sz)
@@ -576,6 +593,10 @@ static void damon_do_apply_schemes(struct damon_ctx *c,
 			}
 			c->primitive.apply_scheme(c, t, r, s);
 			limit->charged_sz += sz;
+			if (limit->sz && limit->charged_sz >= limit->sz) {
+				limit->charge_target_from = t;
+				limit->charge_addr_from = r->ar.end + 1;
+			}
 		}
 		if (s->action != DAMOS_STAT)
 			r->age = 0;
-- 
2.17.1

